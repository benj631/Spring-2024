---
title: "Predicting the Weather"
output: 
  html_document:
    theme: cerulean
    code_folding: hide
    toc: true
    toc_float: true
---

```{r, message=FALSE, warning=FALSE}

library(mosaic)
library(pander)
library(tidyverse)
library(DT)

#April Weather
AW_Cloudy <- read_csv("Weather Prediction Data.csv")
View(AW_Cloudy)

```

## Conclusion

My prediction for the high temperature for Monday, April 29th is: 54.4029$^{\circ}$ Fahrenheit

### Prediction Confidence Interval

```{r}
April2024 <- filter(AW_Cloudy, YearNum == 2024)
April2024_lm <- lm(HighTemp ~ DayNum, data = April2024)
pred_interval <- predict(April2024_lm, newdata = data.frame(DayNum = 120),
                        interval = "prediction", level = 0.95)

pred_interval
```
Our prediction interval has the low at 37.1$^{\circ}$ and the high at 71.7$^{\circ}$

## Weather Graphic


```{r}
library(ggplot2)

# Filter the data for April 2024
April2024 <- filter(AW_Cloudy, YearNum == 2024)

# Fit a linear regression model
April2024_lm <- lm(HighTemp ~ DayNum, data = April2024)

#Interval
pred_interval <- predict(April2024_lm, newdata = data.frame(DayNum = 120),
                         interval = "prediction", level = 0.95)

# Extract coefficients
b <- coef(April2024_lm)


# Create the plot
ggplot(data = April2024, aes(x = DayNum, y = HighTemp)) +
  geom_point() +  # Add points
  geom_abline(intercept = b[1], slope = b[2], color = "red") +  # Add regression line
  geom_point(aes(x = 120, y = pred_interval[1, "fit"]), color = "red", size = 3) +  # Add prediction point
  geom_hline(yintercept = pred_interval[1, "fit"], color = "red", linetype = "dashed") +  # Fitted value line
  geom_hline(yintercept = pred_interval[1, "lwr"], color = "red", linetype = "dashed") +  # Lower bound line
  geom_hline(yintercept = pred_interval[1, "upr"], color = "red", linetype = "dashed") +  # Upper bound line
  xlim(0, 125) + ylim(0, 75) +  # Set limits for x and y axes
  labs(x = "DayNum", y = "HighTemp") +  # Set axis labels
  theme_bw()  # Set theme

print("Prediction: 54.4 Degrees Farenheit")

```

## Background

Even the best experts with great technology struggle to predict the weather. Can we predict the weather with less than 30 days of information?

## Data Selection Methodology and Source

Two immediate methods that one might use to predict the weather for Monday, April 29th, would be to use the previous week from that Monday, either the year past or the year of. The problem with this is that there is rainy and cloudy weather over and headed towards Rexburg. It does not intuitively seem like a smart idea to use data from sunny days to predict cloudy or rainy days. It's possible here that our intuition is misleading, but for now we will trust intuition.

Ultimately, I picked data from cloudy and rainy days from April 2024 and 2023 to predict the temperature. Days that were shown to be at least mostly cloudy for half of the day were selected. The high temperature in April of 2024 for cloudy days has not yet reached above 57$^{\circ}$, and the first day in 2023 that a cloudy day went above 57$^{\circ}$ was April 25th, which reached 59$^{\circ}$. If next week heats up, even following temperature trends, we would expect it to hit around the same value. So, regardless of the regression, we could expect that if Monday is cloudy, and follows the same temperature pattern as 2023, it would end up somewhere between 56-60 degrees. However, we will stick to the regression lines to see what they show.

Acknowledging that the day itself as an explanatory variable is bad, the idea is that selecting days that were mostly cloudy, and expecting Monday to be mostly cloudy means that the day gains some explanatory value.

Data was collected from [timeanddate.com](https://www.timeanddate.com) for the Rexburg area (Fanning Field)

Information was copied from the site into an excel spreadsheet, and loaded here as a csv file.

```{r}
datatable(AW_Cloudy, options=list(lengthMenu = c(6,10,30)), extensions="Responsive")
```

## Model

3 regression lines were ran: 1 for this this years' cloudy April weather, one for 2023, and one with the data combined. But we will use the model that only uses data from April 2024. Here is the model for the data:

$\underbrace{Y_i}_\text{HighTemp} = \underbrace{β_0}_\text{Expected High Temp New Years} + \underbrace{β_1}_\text{Temperature Change Amount by Day in Fareneit}\underbrace{X_i}_\text{Integer Day of the Year} + ϵ_i \text{where} \ \epsilon_i \sim N(0, \sigma^2)$

When β_1 is 0 β_0, is not relevant in this model because we do not care about the weather on new years. The model predicts the high temperature in Fahrenheit with the equation:

$\hat{Y} = 29.5709 + (.2069)X_i$

with $X_i$ being the date as the numbered day of the year.

The null hypothesis is that there will be no correlation between the day and high temperature, and the alternative hypothesis is that there will be a meaningful correlation.

$H_0: \beta_1 = 0$\
$H_a: \beta_1 \neq 0$

### Alpha

We will be using an alpha of .05 to determine p-value significance.

## Regression Lines

Although three regressions were ran, the April 2024 one is what I chose because even though the April 2023 chart has better p values, the weather for this year is probably better for predicting weather for this year than weather from last year.

# April 2024

```{r}
April2024 <- filter(AW_Cloudy,AW_Cloudy$YearNum == 2024)

April2024_lm <- lm(HighTemp ~ DayNum, data= April2024)
summary(April2024_lm) %>% pander()

b <- coef(April2024_lm)

ggplot(data = April2024, aes(x = DayNum, y = HighTemp)) +
  geom_point() +  # Add points
  geom_abline(intercept = b[1], slope = b[2], color = "red") +  # Add regression line
  geom_point(aes(x = 120, y = 54.4029), color = "red", size = 3) +
  xlim(0, 125) + ylim(0, 63) +  # Set limits for x and y axes
  labs(x = "Day of the Year", y = "Highest Temperature Per Day") +  # Set axis labels
  ggtitle("April 2024 Cloudy Weather Only") +
  theme_bw()

predict(April2024_lm,newdata=data.frame(DayNum=120))


```

The above model is using only data from 2024. It has a very low R^2 and no significant p values. In hindsight, choosing this model because it was more recent over last year's model even though it has no significance was a bad choice. All models here were wrong, but it's better to be wrong with something statistically significant than something not statistically significant.

# April 2023

```{r}
April2023 <- filter(AW_Cloudy,AW_Cloudy$YearNum == 2023)
April2023_lm <- lm(HighTemp ~ DayNum, data= April2023)
summary(April2023_lm) %>% pander()

b <- coef(April2023_lm)

ggplot(data = April2023, aes(x = DayNum, y = HighTemp)) +
  geom_point() +  # Add points
  geom_abline(intercept = b[1], slope = b[2], color = "red") +  # Add regression line
  geom_point(aes(x = 120, y = 63.97464 ), color = "red", size = 3) +
  xlim(0, 125) + ylim(0, 75) +  # Set limits for x and y axes
  labs(x = "Day of the Year", y = "Highest Temperature Per Day") +  # Set axis labels
  ggtitle("April 2023 Cloudy Weather Only") +
  theme_bw()

predict(April2023_lm,newdata=data.frame(DayNum=120))


```
This model uses only data from 2023, and had a significant slope. I should have used this one.

# Combined

```{r}
Combined_lm <- lm(HighTemp ~ DayNum, data= AW_Cloudy)
summary(Combined_lm) %>% pander()

b <- coef(Combined_lm)

ggplot(data = AW_Cloudy, aes(x = DayNum, y = HighTemp)) +
  geom_point() +  # Add points
  geom_abline(intercept = b[1], slope = b[2], color = "red") +  # Add regression line
  geom_point(aes(x = 120, y = 51.0607), color = "red", size = 3) +
  xlim(0, 125) + ylim(0, 63) +  # Set limits for x and y axes
  labs(x = "Day of the Year", y = "Highest Temperature Per Day") +  # Set axis labels
  ggtitle("April 2023 and 2024 Combined Data Model") +
  theme_bw()

predict(Combined_lm,newdata=data.frame(DayNum=120))


```
This model was the worst of the three.


# Diagnostic Plots

## 2024 Model Goodness of Fit

Let's examine the diagnostic plots for the 2024 data model.

```{r}
par(mfrow=c(1,3))
plot(April2024_lm, which=1:2)
plot(April2024_lm$residuals, ylab="Residuals")
mtext("Residuals vs Order", side=3)

```

The residuals vs fitted graph is our biggest issue, data points are all over the place. The qq plot actually looks quite good for so few data points. Our residuals vs order are quite scattered. This just shows that regression is not ideal here.

## 2023 Model Goodness of Fit

Let's look at the goodness of fit plots for the model using the 2023 data and see how much better it is.

```{r}
par(mfrow=c(1,3))
plot(April2023_lm, which=1:2)
plot(April2023_lm$residuals, ylab="Residuals")
mtext("Residuals vs Order", side=3)

```
Ironically the plots look much worse than the 2024 model. It's interesting that the slope for this model was significant while no terms were significant in the 2024 model.

# Model Usefulness

Getting a p value of 0.408 tells us that our model's ability to predict high temp according to day is not very good at all. So we cannot reject the null hypothesis.
