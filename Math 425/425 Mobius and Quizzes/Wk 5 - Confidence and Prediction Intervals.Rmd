---
title: "Wk 5 Mobius - Confidence and Prediction Intervals"
author: "Ben Jacobs"
execute:
  keep-md: TRUE
  df-print: paged
  warning: false
format:
  html:
    theme: cerulean
    code-fold: true
    code-line-numbers: true
date: "2024-07-02" 
editor: 
  markdown: 
    wrap: 72
---

```{r}
pacman::p_load(tidyverse,dplyr,car, alr4)
# install.packages("alr4")

```

```{r}

?BGSall

View(BGSall)
```


## Instructions

Use this file to keep a record of your work as you complete the "Skills Quiz: Confidence and Prediction Intervals" assignment in Canvas.


----

<!-- Note: The {} after each Problem and Part header allows you to keep track of what work you have completed. Write something like {Done} once you complete each problem and your html file will then show you a nice summary of what you have "done" already. -->


## Problem 1 {}

Install the `alr4` library in R: `install.packages("alr4")`.

From `library(alr3)` open the `BGSall` data set in R.  As stated in the help file for this data set, this data is a collection of measurements on "children born in 1928-29 in Berkeley, CA."

`> ?BGSall`

`> View(BGSall)`

A standing tradition is that if you measure a child when they are 2-years old, and double their height, this will give a good prediction on their final adult height. Let's see if this is true. 

Perform a regression that could predict a child's 18-year old height from their 2-year old height.

### Part (a) {}

Type out the mathematical equation for this regression model and label both $Y$ and $X$ in the equation.

<div class="YourAnswer">

$$
  \underbrace{Y_i}_\text{Height 18} = \beta_0 + \beta_1 \underbrace{X_i}_\text{Height 2} + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0, \sigma^2)
$$

</div>


### Part (b) {}
 
Plot a scatterplot of the data with your regression line overlaid. Write out the fitted regression equation.

<div class="YourAnswer">

```{r}
bgs.lm <- lm(HT18 ~ HT2, data=BGSall)
summary(bgs.lm)

plot(HT18 ~ HT2, data=BGSall)
abline(bgs.lm)
```

$$
  \underbrace{Y_i}_\text{Height 18} = 45.7966 + 1.4441 \underbrace{X_i}_\text{Height 2} + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0, \sigma^2)
$$

</div>


### Part (c) {}

Report the test statistics and p-values for the following hypotheses. (The hypotheses about $\beta_0$ claim that at age 0-years, a child should have height 0 cm. The hypotheses about $\beta_1$ claim that height doubles from age 2 to 18.)

$$ 
  \begin{array}{l}
    H_0: \beta_0 = 0 \\
    H_a: \beta_0 \neq 0 \\
  \end{array} \quad 
  \begin{array}{l}
    H_0: \beta_1 = 2 \\
    H_a: \beta_1 \neq 2 \\
  \end{array}
$$

<div class="YourAnswer">

```{r}
b <- coef(bgs.lm)

model <- bgs.lm

# Coefficients and their standard errors
b <- coef(model)
se <- sqrt(diag(vcov(model)))

# Null values
null_b0 <- 0
null_b1 <- 2

# T-statistics
t_b0 <- (b[1] - null_b0) / se[1]
t_b1 <- (b[2] - null_b1) / se[2]

# Display t-statistics
t_b0
t_b1

# Performing the t-tests
p_value_b0 <- 2 * pt(-abs(t_b0), df = model$df.residual)
p_value_b1 <- 2 * pt(-abs(t_b1), df = model$df.residual)

```


```{r}
t_b0
t_b1

# Display p-values
p_value_b0
p_value_b1
```

Type your answer here...

</div> 
 
 
### Part (d) {}


State the slope, y-intercept, and $R^2$ of this regression. Further, provide 95% confidence intervals for the slope and intercept. Interpret the values.

<div class="YourAnswer">

```{r}
conf_intervals <- confint(bgs.lm, level = 0.95)
print(conf_intervals)
```

Type your answer here...

</div>


### Part (e) {}

Create a residuals vs fitted-values plot and Q-Q Plot of the residuals for this regression. What do these plots show?

<div class="YourAnswer">

```{r}
plot(bgs.lm, which=1:3)
```

</div>



### Part (f) {}

A certain stats teacher at BYU-Idaho has a son named Andrew who turns 2-years old in a couple of weeks. He is currently 2 feet 9 inches tall. Predict his 18-year old height in centimeters with 95% confidence.

<div class="YourAnswer">

```{r}
twoyo.pred <- predict(bgs.lm, data.frame(HT2=(33*2.54)))
twoyo.pred

HT2_cm <- 33 * 2.54  # 33 inches converted to centimeters

# Compute confidence interval for prediction
pred_conf_int <- predict(bgs.lm, newdata = data.frame(HT2 = HT2_cm),
                         interval = "confidence", level = 0.95)

# Display the confidence interval
pred_conf_int
```

```{r}
# Calculate Confidence Interval

X_h <- 33 * 2.54  # Example: 33 inches converted to centimeters

# Step 2: Obtain mean of predictor variable X (barX)
barX <- mean(Clothing$HT2)  # Replace with your actual variable and dataset

# Step 3: Calculate sum of squares of deviations of Xi from its mean (sum(Xi - barX)^2)
sum_Xi_barX_sq <- sum((Clothing$HT2 - barX)^2)  # Replace with your actual variable and dataset

# Step 4: Calculate n (number of observations)
n <- nrow(Clothing)  # Replace with the actual number of observations in your dataset

# Step 5: Obtain MSE (mean squared error) from your regression model (bgs.lm)
MSE <- deviance(bgs.lm) / bgs.lm$df.residual  # Replace with the actual MSE calculation from your model

# Step 6: Calculate the standard error of prediction (s_Yh_hat)
s_Yh_hat <- MSE * (1 + 1/n + (X_h - barX)^2 / sum_Xi_barX_sq)

# Step 7: Determine the critical value from the t-distribution for desired confidence level (e.g., 95%)
# For a 95% confidence interval and n-2 degrees of freedom:
t_star <- qt(0.975, df = bgs.lm$df.residual)  # 0.975 for 95% CI (two-tailed test)

# Step 8: Compute the lower and upper bounds of the prediction interval
prediction <- predict(bgs.lm, newdata = data.frame(HT2 = X_h), interval = "prediction", level = 0.95)

# Step 9: Print the prediction interval
prediction
```



</div>


----

## Problem 2 {}

Open the `wblake` data set from library(alr3).

```{r}
?wblake

View(wblake)
```


If you love fishing, then you might like this data. The goal of this data was to see if there was a link in the radius size of a key "Scale" of a fish and the overall "Length" of the fish.

### Part (a) {}

Type out the mathematical equation for this regression model and label both $Y$ and $X$ in the equation.

<div class="YourAnswer">

$$
  \underbrace{Y_i}_\text{Scale} = \beta_0 + \beta_1 \underbrace{X_i}_\text{Length} + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0, \sigma^2)
$$

</div>


### Part (b) {}
 
Plot a scatterplot of the data with your regression line overlaid. Write out the fitted regression equation. State the $R^2$ value of the regression.

<div class="YourAnswer">

```{r}
wb.lm <- lm(Scale ~ Length, data=wblake)
summary(wb.lm)

plot(Scale ~ Length, data=wblake)
abline(wb.lm)
```

$$
  \underbrace{Y_i}_\text{Scale} = -1.4307592 + 0.0378026 \underbrace{X_i}_\text{Length} + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0, \sigma^2)
$$

</div>


### Part (c) {}

Diagnose the regression with a residuals vs. fitted-values plot. Determine which Y-transformation is suggested for this data.

<div class="YourAnswer">

```{r}
plot(wb.lm, which=1:3)
```


```{r}
boxCox(wb.lm)
```
sqrt transform is best 


</div> 
 
 
### Part (d) {}

Perform a regression of the form $Y' = Y^\lambda$. Use your answer to Part (c) to select $\lambda$.

Plot the regression in the transformed space, $Y' \sim X$ and add the fitted regression to the plot. 

<div class="YourAnswer">

```{r}
wb.sq.lm <- lm(sqrt(Scale) ~ Length, data=wblake)
summary(wb.lm)

plot(sqrt(Scale) ~ Length, data=wblake)
abline(wb.sq.lm)
```

Type your answer here...

</div>  
 
### Part (e) {}

State the slope, y-intercept, and $R^2$ of this transformed regression. 

<div class="YourAnswer">

```{r}
b <- coef(wb.sq.lm)
print(b[1])
print("+")
print(b[2])
print("* X1")
```

Type your answer here...

</div>


### Part (f) {}

Create a residuals vs fitted-values plot and Q-Q Plot of the residuals for this trasnformed regression. Does this regression look better than the original?

<div class="YourAnswer">

```{r}
plot(wb.sq.lm,which=1:3)
```

</div>
 

### Part (g) {}

Untransform the fitted regression equation and draw it on a scatterplot of the original data. Include the original regression line on this plot. 

<div class="YourAnswer">

```{r}
wb.sq.lm <- lm(sqrt(Scale) ~ Length, data = wblake)

# Summary of the linear regression model
summary(wb.sq.lm)

# Retrieve coefficients from the model
b <- coef(wb.sq.lm)

# Define a function to untransform the predicted values
untransformed <- function(x) {
  (b[1] + b[2] * x)^2
}

# Scatter plot of the data
plot(Scale ~ Length, data = wblake)

# Add the untransformed regression line
curve(untransformed(x), add = TRUE, col = "red", lwd = 2)

# Add labels and title
title(main = "Scatter Plot with Untransformed Regression Line")
xlabel <- expression(Length)
ylabel <- expression(Scale)
xlabel <- bquote(.(xlabel) ~ (cm))
ylabel <- bquote(.(ylabel) ~ (sqrt(m^2)))
```

</div>



### Part (h) {}

Place two prediction intervals for the Scale radius when the Length of the fish is 250 on your scatterplot of the data in the original units.

1. Show the prediction interval from the original regression in the original units. 

2. Show the prediction interval from the transformed regression back on the original units.

<div class="YourAnswer">

```{r}
# Fit the original linear regression model
wb.lm <- lm(Scale ~ Length, data = wblake)

# Fit the transformed linear regression model
wb.sq.lm <- lm(sqrt(Scale) ~ Length, data = wblake)

# Specify the new value of Length for prediction
new_length <- 250

# Compute prediction intervals for the original regression (wb.lm)
pred_original <- predict(wb.lm, newdata = data.frame(Length = new_length),
                         interval = "prediction", level = 0.95)

# Compute prediction intervals for the transformed regression (wb.sq.lm)
# First, transform the prediction interval back to original units
pred_transformed <- predict(wb.sq.lm, newdata = data.frame(Length = new_length),
                            interval = "prediction", level = 0.95)
pred_transformed_original_units <- pred_transformed^2

# Scatter plot of the data
plot(Scale ~ Length, data = wblake, main = "Scatter Plot with Prediction Intervals")

# Add prediction intervals from original regression in original units
lines(rep(new_length, 3), pred_original[, c("fit", "lwr", "upr")], col = "blue", lwd = 2, lty = 1)

# Add prediction intervals from transformed regression back in original units
lines(rep(new_length, 3), pred_transformed_original_units[, c("fit", "lwr", "upr")], col = "red", lwd = 2, lty = 1)

# Add horizontal dashed lines for each equation
abline(h = pred_original[1], col = "blue", lwd = 2, lty = 2)
abline(h = pred_original[2], col = "blue", lwd = 2, lty = 2)
abline(h = pred_original[3], col = "blue", lwd = 2, lty = 2)

abline(h = pred_transformed_original_units[1], col = "red", lwd = 2, lty = 2)
abline(h = pred_transformed_original_units[2], col = "red", lwd = 2, lty = 2)
abline(h = pred_transformed_original_units[3], col = "red", lwd = 2, lty = 2)

# Add legend
legend("topright", legend = c("Original Regression", "Transformed Regression"),
       col = c("blue", "red"), lwd = 2, lty = c(1, 1), bty = "n")

# Add labels
xlabel <- expression(Length)
ylabel <- expression(Scale)
xlabel <- bquote(.(xlabel) ~ (cm))
ylabel <- bquote(.(ylabel) ~ (mm))

# Add title and labels
title(main = "Scatter Plot with Prediction Intervals and Horizontal Lines")

# Show the plot


```

```{r}
pred_original
pred_transformed_original_units
```


</div>


----



<style>

.YourAnswer {
  color: #317eac;
  padding: 10px;
  border-style: solid;
  border-width: 2px;
  border-color: skyblue4;
  border-radius: 5px;
}

</style>

 
 